{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>or i just worry too much?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Juuuuuuuuuuuuuuuuussssst Chillin!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunny Again        Work Tomorrow  :-|  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>handed in my uniform today . i miss you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>hmmmm.... i wonder how she my number @-)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment                                      SentimentText\n",
       "0       1          0                       is so sad for my APL frie...\n",
       "1       2          0                     I missed the New Moon trail...\n",
       "2       3          1                            omg its already 7:30 :O\n",
       "3       4          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4       5          0           i think mi bf is cheating on me!!!   ...\n",
       "5       6          0                  or i just worry too much?        \n",
       "6       7          1                 Juuuuuuuuuuuuuuuuussssst Chillin!!\n",
       "7       8          0         Sunny Again        Work Tomorrow  :-|  ...\n",
       "8       9          1        handed in my uniform today . i miss you ...\n",
       "9      10          1           hmmmm.... i wonder how she my number @-)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "df = pd.read_csv('twitter.csv', encoding='latin-1', nrows=10)\n",
    "# df = pd.read_csv('twitter.csv', encoding='latin-1')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APL ORG\n",
      "New Moon LOC\n",
      "7:30 TIME\n",
      "11 CARDINAL\n",
      "2 CARDINAL\n",
      "mi bf PERSON\n",
      "Juuuuuuuuuuuuuuuuussssst Chillin PERSON\n",
      "Tomorrow DATE\n",
      "Tonight TIME\n",
      "today DATE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my  friend....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the  trailer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already  :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think  is cheating on me!!!       T_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>or i just worry too much?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunny Again        Work   :-|       TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>handed in my uniform  . i miss you already</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>hmmmm.... i wonder how she my number @-)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment                                      SentimentText\n",
       "0       1          0                       is so sad for my  friend....\n",
       "1       2          0                           I missed the  trailer...\n",
       "2       3          1                                omg its already  :O\n",
       "3       4          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4       5          0            i think  is cheating on me!!!       T_T\n",
       "5       6          0                  or i just worry too much?        \n",
       "6       7          1                                                 !!\n",
       "7       8          0            Sunny Again        Work   :-|       TV \n",
       "8       9          1         handed in my uniform  . i miss you already\n",
       "9      10          1           hmmmm.... i wonder how she my number @-)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "'''\n",
    "def RemoveNER(text):\n",
    "    filtered = []\n",
    "    tokens = word_tokenize(text)\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    for index, var in enumerate(text):\n",
    "        aux=0\n",
    "        doc = nlp(text[index])\n",
    "        for x in tokens:\n",
    "            if(len(doc.ents)>0):\n",
    "                if(x==doc.ents[aux].text):\n",
    "                    if(aux<len(doc.ents)):\n",
    "                        aux+=1\n",
    "                else:\n",
    "                    filtered.append(x)\n",
    "        print(filtered)\n",
    "    new_filtered = ' '.join(filtered)\n",
    "    return new_filtered\n",
    "\n",
    "df['SentimentText'] = df['SentimentText'].apply(RemoveNER)\n",
    "#RemoveNER(\"Justin drift in car in Brazil\")\n",
    "'''\n",
    "\n",
    "def IdentifyNER(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    for entity in doc.ents:\n",
    "        print(entity.text, entity.label_)\n",
    "        text = text.replace(entity.text, \"\")\n",
    "    return text\n",
    "\n",
    "df['SentimentText'] = df['SentimentText'].apply(lambda x: IdentifyNER(x))\n",
    "\n",
    "# Show the cleaned text\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sad friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>missed trailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg already</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>omgaga im sooo im gunna cry ive dentist since ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>think cheating tt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>worry much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>sunny work tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>handed uniform miss already</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>hmmmm wonder number</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment                                      SentimentText\n",
       "0       1          0                                         sad friend\n",
       "1       2          0                                     missed trailer\n",
       "2       3          1                                        omg already\n",
       "3       4          0  omgaga im sooo im gunna cry ive dentist since ...\n",
       "4       5          0                                  think cheating tt\n",
       "5       6          0                                         worry much\n",
       "6       7          1                                                   \n",
       "7       8          0                                      sunny work tv\n",
       "8       9          1                        handed uniform miss already\n",
       "9      10          1                                hmmmm wonder number"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the text\n",
    "\n",
    "# Function for clean text\n",
    "def CleanTxt(text):\n",
    "    text = re.sub(u'[^a-zA-Z0-9áéíóúÁÉÍÓÚâêîôÂÊÎÔãõÃÕçÇ: ]', '', text)\n",
    "    return text\n",
    "\n",
    "# Function for remove stop words\n",
    "def RemoveStopWords(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words=[w for w in tokens if w not in string.punctuation and w not in stop_words]\n",
    "    \n",
    "    new_words = ' '.join(words)\n",
    "\n",
    "    return new_words\n",
    "\n",
    "# Cleaning the text\n",
    "df['SentimentText'] = df['SentimentText'].apply(CleanTxt)\n",
    "df['SentimentText'] = df['SentimentText'].apply(RemoveStopWords)\n",
    "\n",
    "# Show the cleaned text\n",
    "df.head(10)\n",
    "# print(df['SentimentText'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sad friend</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>missed trailer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>omg already</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>omgaga im sooo im gunna cry ive dentist since ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>think cheating tt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>worry much</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sunny work tv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>handed uniform miss already</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hmmmm wonder number</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       SentimentText  Sentiment\n",
       "0                                         sad friend          0\n",
       "1                                     missed trailer          0\n",
       "2                                        omg already          1\n",
       "3  omgaga im sooo im gunna cry ive dentist since ...          0\n",
       "4                                  think cheating tt          0\n",
       "5                                         worry much          0\n",
       "6                                                             1\n",
       "7                                      sunny work tv          0\n",
       "8                        handed uniform miss already          1\n",
       "9                                hmmmm wonder number          1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df = df[['SentimentText','Sentiment']]\n",
    "tweet_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = df.SentimentText.values\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(tweet)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "encoded_docs = tokenizer.texts_to_sequences(tweet)\n",
    "padded_sequence = pad_sequences(encoded_docs, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 3 4]\n"
     ]
    }
   ],
   "source": [
    "# print(tokenizer.word_index)\n",
    "# print(tweet[0])\n",
    "# print(encoded_docs[0])\n",
    "print(padded_sequence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vinicius/ner/lib/python3.6/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/vinicius/ner/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/vinicius/ner/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 32)           1088      \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 200, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 50)                16600     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 17,739\n",
      "Trainable params: 17,739\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_vector_length,     \n",
    "                                     input_length=200) )\n",
    "model.add(SpatialDropout1D(0.25))\n",
    "model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', \n",
    "                           metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 115ms/sample - loss: 0.6952 - acc: 0.1250 - val_loss: 0.7007 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 19ms/sample - loss: 0.6954 - acc: 0.5000 - val_loss: 0.7060 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 25ms/sample - loss: 0.6893 - acc: 0.7500 - val_loss: 0.7106 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 21ms/sample - loss: 0.6841 - acc: 0.7500 - val_loss: 0.7154 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 20ms/sample - loss: 0.6776 - acc: 0.7500 - val_loss: 0.7205 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 20ms/sample - loss: 0.6699 - acc: 0.8750 - val_loss: 0.7258 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 21ms/sample - loss: 0.6797 - acc: 0.7500 - val_loss: 0.7313 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 46ms/sample - loss: 0.6756 - acc: 0.7500 - val_loss: 0.7368 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 33ms/sample - loss: 0.6679 - acc: 0.7500 - val_loss: 0.7424 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 20ms/sample - loss: 0.6564 - acc: 0.8750 - val_loss: 0.7487 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 48ms/sample - loss: 0.6557 - acc: 0.7500 - val_loss: 0.7556 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 39ms/sample - loss: 0.6545 - acc: 0.7500 - val_loss: 0.7629 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 21ms/sample - loss: 0.6841 - acc: 0.7500 - val_loss: 0.7700 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 36ms/sample - loss: 0.6467 - acc: 0.7500 - val_loss: 0.7777 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 36ms/sample - loss: 0.6271 - acc: 0.7500 - val_loss: 0.7865 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 20ms/sample - loss: 0.6459 - acc: 0.7500 - val_loss: 0.7965 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 28ms/sample - loss: 0.6450 - acc: 0.7500 - val_loss: 0.8071 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 41ms/sample - loss: 0.6095 - acc: 0.7500 - val_loss: 0.8193 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 42ms/sample - loss: 0.6136 - acc: 0.7500 - val_loss: 0.8334 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 35ms/sample - loss: 0.6220 - acc: 0.7500 - val_loss: 0.8493 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "sentiment_label = df.Sentiment.factorize()\n",
    "\n",
    "history = model.fit(padded_sequence,sentiment_label[0],\n",
    "                  validation_split=0.2, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word =\"This is soo happy\"\n",
    "tw = tokenizer.texts_to_sequences([test_word])\n",
    "tw = pad_sequences(tw,maxlen=200)\n",
    "prediction = int(model.predict(tw).round().item())\n",
    "sentiment_label[1][prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
